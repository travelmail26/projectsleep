{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/travelmail26/projectsleep/blob/main/Muse_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CJwDS6n7xmN"
      },
      "outputs": [],
      "source": [
        "!pip install mne\n",
        "!pip install yasa\n",
        "!pip install datashader\n",
        "import pandas as pd\n",
        "import mne\n",
        "import numpy as np\n",
        "import yasa\n",
        "import matplotlib as plt\n",
        "import datashader as ds\n",
        "import datashader.transfer_functions as tf\n",
        "from IPython.display import display\n",
        "import seaborn as sns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cn2ObqiCIEBe"
      },
      "outputs": [],
      "source": [
        "##load files\n",
        "\n",
        "#dataFile = pd.read_csv(\"/content/stimulant_mindMonitor_2023-01-18--14-37-14.csv\", skiprows=0, usecols=[*range(1,21)])\n",
        "#url = 'https://www.dropbox.com/s/ttv6vxh3ys7q0ou/mindMonitor_2023-01-18--14-37-14.csv?dl=1'\n",
        "url = 'https://www.dropbox.com/s/a5uwkqaq71mkrxp/mindMonitor_2023-02-17--18-29-44_choc_intervention.csv?dl=1'\n",
        "urlmantrameditation = 'https://www.dropbox.com/s/z09umrre7qgg4ld/mindMonitor_2023-02-23--08-01-50_eyesopen_eyesclose_mantrameditation_eyesopen_eyesclosed.csv?dl=1'\n",
        "urlmantra2 = 'https://www.dropbox.com/s/z0eoyhwinrep224/mindMonitor_2023-03-28--10-43-44_after_breakfast_baseline_mantra__3_intervention_breathfocus_4.csv?dl=1'\n",
        "#dataFile = pd.read_csv('/content/mindMonitor_2023-01-18--14-37-14.csv', skiprows=0, usecols=[*range(1,21)])\n",
        "urlsleep = 'https://www.dropbox.com/s/hu50afgorep21c6/mindMonitor_2023-04-03--01-28-07_sleep.csv?dl=1'\n",
        "#dfraw = pd.read_csv('/content/mindMonitor_2023-01-18--14-37-14.csv')\n",
        "\n",
        "#dfraw = pd.read_csv('/content/mindMonitor_2023-02-15--14-48-03_stiumant_limited_interventions.csv')\n",
        "#dfraw = pd.read_csv('/content/mindMonitor_2023-02-23--08-01-50_eyesopen_eyesclose_mantrameditation_eyesopen_eyesclosed.csv')\n",
        "#dfraw = pd.read_csv('/content/mindMonitor_2023-02-23--08-01-50_eyesopen_eyesclose_mantrameditation_eyesopen_eyesclosed.csv')\n",
        "#urlsleep58 = 'https://www.dropbox.com/s/9r516639sms98sj/mindMonitor_2023-05-07--23-31-37_5188390995226691787_sleep.csv?dl=1'\n",
        "urlsleep614 = 'https://www.dropbox.com/s/s21a5x5z1riy8jt/mindMonitor_2023-06-14--01-27-28_2365017561881232972.csv?dl=1'\n",
        "urlsleep615 = 'https://www.dropbox.com/s/q37nqho2xmprdgz/mindMonitor_2023-06-15--00-27-29_8457076698113972093.csv?dl=1'\n",
        "urlbreathingshorttest = 'https://www.dropbox.com/s/d5twz43yv7xqrwl/breathing_example_1035am.m4a?dl=1'\n",
        "urlbreathingshorttestmuse = 'https://www.dropbox.com/s/ykv1p3ao8jt1a39/mindMonitor_2023-07-12--10-35-02_8991128292079486402_breathing_test.csv?dl=1'\n",
        "urlaudiobreathsleep71623 = 'https://www.dropbox.com/s/nusz42jgkdv6n5x/sleep71623135.m4a?dl=1'\n",
        "urlsleep719 = 'https://www.dropbox.com/s/dw9iqtfx9djpekc/mindMonitor_2023-07-19--01-28-39_673531789350893158_muses2.csv?dl=1'\n",
        "urlsleep721 = 'https://www.dropbox.com/s/ce7gh2j95vrsh9p/mindMonitor_2023-07-21--08-32-56_7241060858940157562_morning_dreamt.csv?dl=1'\n",
        "urlsleep724 = 'https://www.dropbox.com/s/yu41zvnbxb5uwn3/mindMonitor_2023-07-23--00-23-56_disconap_insomnia_sweets_processedsweets_2_maybe_reduction.csv?dl=1'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load audio files\n",
        "\n",
        "import io\n",
        "import requests\n",
        "\n",
        "# Get the Dropbox URL of the object\n",
        "\n",
        "# Download the object from Dropbox\n",
        "response = requests.get(urlbreathingshorttest, stream=True)\n",
        "\n",
        "# REWRITE FILE NAME Save the object in Google Colab's file structure\n",
        "with open(\"breathing_example.m4a\", \"wb\") as f:\n",
        "  for chunk in response.iter_content(chunk_size=1024):\n",
        "    f.write(chunk)"
      ],
      "metadata": {
        "id": "2wzX-wLtnfv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load file\n",
        "\n",
        "dfraw = pd.read_csv(urlsleep615)\n",
        "\n",
        "\n",
        "df = dfraw"
      ],
      "metadata": {
        "id": "EzqrqZWsW8pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rv82Xuof2aSp"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W6uRkM4-d1e"
      },
      "outputs": [],
      "source": [
        "#pd.to_timedelta(df['TimeStamp']).head()\n",
        "from datetime import datetime\n",
        "\n",
        "df['TimeStamp'] = pd.to_datetime(df['TimeStamp'])\n",
        "time0 = df['TimeStamp'].loc[0]\n",
        "\n",
        "df['elapsed'] = 'NA'\n",
        "\n",
        "#df['Results'] = ['Pass' if m>=33 else 'Fail' for m in df['Marks']]\n",
        "for row in range(1,len(df),1):\n",
        "    time1 = df['TimeStamp'].loc[row]\n",
        "    time1 = pd.Timestamp(time1)\n",
        "    df['elapsed'].loc[row] = pd.Timedelta(time1-time0).total_seconds()\n",
        "\n",
        "df['elapsed'] = pd.to_numeric(df['elapsed'], errors='coerce')\n",
        "df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9gOAlydhcJS"
      },
      "outputs": [],
      "source": [
        "#for original dataset\n",
        "\n",
        "import numpy as np\n",
        "# conditions = [\n",
        "#     (df['elapsed'] <= 2),\n",
        "#     (df['elapsed'] > 2) & (df['elapsed'] <= 9),\n",
        "#     (df['elapsed'] > 9) & (df['elapsed'] <= 15),\n",
        "#     (df['elapsed'] > 15)\n",
        "#     ]\n",
        "\n",
        "# # create a list of the values we want to assign for each condition\n",
        "# values = ['tier_4', 'tier_3', 'tier_2', 'tier_1']\n",
        "\n",
        "# # create a new column and use np.select to assign values to it using our lists as arguments\n",
        "# df['tier'] = np.select(conditions, values)\n",
        "\n",
        "# display updated DataFrame\n",
        "# df.head()\n",
        "\n",
        "conditions = [\n",
        "    (df['elapsed'] <= 12),\n",
        "    (df['elapsed'] > 12) & (df['elapsed'] <= 70),\n",
        "    (df['elapsed'] > 77) & (df['elapsed'] <= 134),\n",
        "     (df['elapsed'] > 134) & (df['elapsed'] <= 237),\n",
        "     (df['elapsed'] > 237) & (df['elapsed'] <= 370),\n",
        "    (df['elapsed'] > 370)\n",
        "    ]\n",
        "\n",
        "# create a list of the values we want to assign for each condition\n",
        "values = ['eyesClosed1', 'thinking', 'eyesClosed2', 'intervention', 'postTreatment', 'finish']\n",
        "\n",
        "# create a new column and use np.select to assign values to it using our lists as arguments\n",
        "df['mindful'] = np.select(conditions, values)\n",
        "\n",
        "\n",
        "\n",
        "eyesClosed1 = 12 #00:12\n",
        "thinking = 70 #01:10\n",
        "eyesClosed2 = 77 #01:17\n",
        "intervention = 134 #02:14\n",
        "postTreatment = 237 #03:57\n",
        "finish = 370 #06:10\n",
        "\n",
        "# display updated DataFrame\n",
        "df.head(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR83ZGMvpP7m"
      },
      "outputs": [],
      "source": [
        "#for stimulant limted dataset\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "conditions = [\n",
        "    (df['elapsed'] <= 40),\n",
        "    (df['elapsed'] > 40)\n",
        "    ]\n",
        "\n",
        "# create a list of the values we want to assign for each condition\n",
        "values = ['before intervention', 'after intervention']\n",
        "\n",
        "# create a new column and use np.select to assign values to it using our lists as arguments\n",
        "df['mindful'] = np.select(conditions, values)\n",
        "\n",
        "# display updated DataFrame\n",
        "df.head(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wdniMMZNrtY"
      },
      "outputs": [],
      "source": [
        "# dataMin = readData.min().min()\n",
        "# dataMax = readData.max().max()\n",
        "# normData = readData.copy()\n",
        "\n",
        "# for col in normData.columns:\n",
        "#     normData[col] = normData[col]-dataMin / dataMax-dataMin\n",
        "\n",
        "df['Theta_AF7_norm'] = df['Theta_AF7']-df['Theta_AF7'].min() / (df['Theta_AF7'].max()-df['Theta_AF7'].min())\n",
        "df['Beta_AF7_norm'] = df['Beta_AF7']-df['Beta_AF7'].min() / (df['Beta_AF7'].max()-df['Beta_AF7'].min())\n",
        "df['ThetaBetaRatio_AF7_norm'] = df['Theta_AF7_norm'] / df['Beta_AF7_norm']\n",
        "\n",
        "\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgly4uGyw0eH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6C6Eua6kEIc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "#grouped =df.groupby(['mindful'])['ThetaBetaRatio_AF7_norm'].median()\n",
        "grouped =df.groupby(['mindful'])['Gamma_AF7'].median()\n",
        "\n",
        "#for original dataset\n",
        "print(grouped.reset_index(inplace=False))\n",
        "\n",
        "# sns.lineplot(x='mindful', y='ThetaBetaRatio_AF7_norm', data=grouped.reset_index())\n",
        "\n",
        "#for stimulant limited dataset\n",
        "\n",
        "sns.histplot(x='mindful', y='Gamma_AF7', data=grouped.reset_index())\n",
        "\n",
        "\n",
        "plt.xticks(rotation=45)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ry2xF-jlljMV"
      },
      "outputs": [],
      "source": [
        "print(df.index)\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "#df['interpolated'] = interp1d(df['elapsed'], df['ThetaBetaRatio_AF7_norm'], kind='cubic')\n",
        "\n",
        "\n",
        "#ax = sns.lineplot(x='elapsed', y='ThetaBetaRatio_AF7_norm', data=df.sample(frac=1))\n",
        "ax = sns.lineplot(x='TimeStamp', y='Gamma_AF7', data=dfs)\n",
        "\n",
        "#ax2 = sns.lineplot(x='elapsed', y='Gamma_AF7', data=df.sample(frac=0.2))\n",
        "\n",
        "ax.set(ylim=(-0.7, 6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHdWSbZgo9Ct"
      },
      "outputs": [],
      "source": [
        "dfsec = df.rolling(256, min_periods=1).mean()\n",
        "dfsec.head()\n",
        "#dfs = dfsec.iloc[::30, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIBRr19cYGpD"
      },
      "source": [
        "# exploratory analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPMxSE9OYI1q"
      },
      "outputs": [],
      "source": [
        "#load\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#url = 'https://www.dropbox.com/s/uq60t8qy33i21dt/mindMonitor_2023-02-14--09-43-07_huberman_cyclic_breath_work.csv?dl=1'\n",
        "dfraw = pd.read_csv(urlsleep724)\n",
        "\n",
        "dfraw.head()\n",
        "df = dfraw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko_VjyJLaYjc"
      },
      "outputs": [],
      "source": [
        "# reduce file size\n",
        "\n",
        "# df = (dfraw.select_dtypes('number')\n",
        "#    .rolling(256, min_periods=1).mean()\n",
        "#    .join(dfraw.select_dtypes(exclude='number'))\n",
        "#    [dfraw.columns]\n",
        "#  )\n",
        "\n",
        "# df = df[::512]\n",
        "\n",
        "# print ('length of df', len(df))\n",
        "\n",
        "# df.head(20)\n",
        "\n",
        "#reduce 0.5 second intervals to 10 second rolling average\n",
        "\n",
        "df = (dfraw.select_dtypes('number')\n",
        "   .rolling(150, min_periods=1).mean()\n",
        "   .join(dfraw.select_dtypes(exclude='number'))\n",
        "   [dfraw.columns]\n",
        " )\n",
        "\n",
        "df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG6D0-kwb4GV"
      },
      "outputs": [],
      "source": [
        "#norming data and ratio\n",
        "\n",
        "\n",
        "df['Theta_AF8_norm'] = (df['Theta_AF8']-df['Theta_AF8'].min()) / ((df['Theta_AF8'].max()-df['Theta_AF8'].min()))\n",
        "df['Theta_AF8_norm'] = (df['Theta_AF8']-df['Theta_AF8'].min()) / ((df['Theta_AF8'].max()-df['Theta_AF8'].min()))\n",
        "\n",
        "df['Beta_AF8_norm'] = (df['Beta_AF8']-df['Beta_AF8'].min()) / ((df['Beta_AF8'].max()-df['Beta_AF8'].min()))\n",
        "df['Beta_AF7_norm'] = (df['Beta_AF7']-df['Beta_AF7'].min()) / ((df['Beta_AF7'].max()-df['Beta_AF7'].min()))\n",
        "\n",
        "\n",
        "df['Beta_AF8_af7_combined_norm'] = df['Beta_AF8_norm'] + df['Beta_AF7_norm']\n",
        "\n",
        "\n",
        "\n",
        "df['ThetaBetaRatio_AF8_norm'] = df['Theta_AF8_norm'] / df['Beta_AF8_norm']\n",
        "\n",
        "df['Delta_AF7_norm'] = (df['Delta_AF7']-df['Delta_AF7'].min()) / ((df['Delta_AF7'].max()-df['Delta_AF7'].min()))\n",
        "\n",
        "\n",
        "df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert time column to datetime\n",
        "df['time'] = pd.to_datetime(df['TimeStamp'])\n",
        "\n",
        "# Resample the data to minute intervals and calculate the mean\n",
        "df_resampled = df.resample('1T', on='time').mean()\n",
        "\n",
        "# Reset the index\n",
        "df_resampled.reset_index(inplace=True)\n",
        "\n",
        "# Calculate the relative frequency\n",
        "total_power = np.power(10, df_resampled[\"Alpha_AF8\"]) + np.power(10, df_resampled[\"Beta_AF8\"]) + np.power(10, df_resampled[\"Theta_AF8\"]) + np.power(10, df_resampled[\"Delta_AF8\"])\n",
        "df_resampled[\"Alpha_AF8\"] = np.power(10, df_resampled[\"Alpha_AF8\"]) / total_power\n",
        "df_resampled[\"Beta_AF8\"] = np.power(10, df_resampled[\"Beta_AF8\"]) / total_power\n",
        "df_resampled[\"Theta_AF8\"] = np.power(10, df_resampled[\"Theta_AF8\"]) / total_power\n",
        "df_resampled[\"Delta_AF8\"] = np.power(10, df_resampled[\"Delta_AF8\"]) / total_power\n",
        "\n",
        "# Melt the dataframe to long format for easier plotting with seaborn\n",
        "df_melted = df_resampled.melt(id_vars='time', value_vars=['Alpha_AF8', 'Beta_AF8', 'Theta_AF8', 'Delta_AF8'])\n",
        "\n",
        "# Create the line plot\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.lineplot(data=df_melted, x='time', y='value', hue='variable')\n",
        "plt.title(\"Relative Brain Wave Frequencies for AF8 Channel\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xCunY3EsHuh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsR7dzQEb9UR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "\n",
        "#ax = sns.lineplot(x='TimeStamp', y='Beta_AF8_af7_combined_norm', data=df, ax=ax )\n",
        "\n",
        "ax = sns.lineplot(x='TimeStamp', y='Delta_AF7', data=df, ax=ax )\n",
        "\n",
        "ax.set_xlabel('TimeStamp')\n",
        "ax.set_ylabel('Normalized Values')\n",
        "plt.show()\n",
        "\n",
        "ax.set(ylim=(-0.5, 3))\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(100))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ppg analysis\n",
        "\n",
        "50hz is suggeste minimal sampling rate for heart reate variability\n",
        "\n",
        "https://www.sciencedirect.com/science/article/pii/S1746809421001865\n",
        "\n",
        "filters for ppg\n",
        "https://www.nature.com/articles/sdata201876#:~:text=In%20addition%20to%20physiological%20information,chosen%20according%20to%20their%20purpose.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9cEKJb2AXCBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "13CLeTj3cqHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = df[::5]\n",
        "print(len(dfs))"
      ],
      "metadata": {
        "id": "cn9IcQF3cXQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "OZTzdY5cXEG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "dfs = df.iloc[:30000:10]\n",
        "\n",
        "# Create a figure with two subplots\n",
        "fig, axes = plt.subplots(3, 1, figsize=(20, 5))\n",
        "\n",
        "# Plot the first lineplot\n",
        "sns.lineplot(data=dfs, x='TimeStamp', y=\"PPG_IR\", ax=axes[0])\n",
        "axes[0].set(xlabel='TimeStamp', ylabel='PPG_IR')\n",
        "\n",
        "# Plot the second lineplot\n",
        "sns.lineplot(data=dfs, x='TimeStamp', y=\"PPG_Red\", ax=axes[1])\n",
        "axes[1].set(ylabel='PPG_Red')\n",
        "\n",
        "# Plot the second lineplot\n",
        "sns.lineplot(data=dfs, x='TimeStamp', y=\"PPG_Ambient\", ax=axes[2])\n",
        "axes[1].set(ylabel='PPG_Red')\n",
        "\n",
        "# Show the figure\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "axbG3VjHZoOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmUIOcj7RdTJ"
      },
      "source": [
        "##entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJQX8CQdRcFP"
      },
      "outputs": [],
      "source": [
        "!pip install antropy\n",
        "import antropy as ant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "384ZL1swRq1m"
      },
      "outputs": [],
      "source": [
        "len(df)\n",
        "\n",
        "#https://www.analyticsvidhya.com/blog/2020/11/entropy-a-key-concept-for-all-data-science-beginners/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msC_sxSAR6oc"
      },
      "outputs": [],
      "source": [
        "dfs = df.iloc[3500:]\n",
        "x = dfs['Beta_AF8_norm'][df['Beta_AF8_norm'].notna()]\n",
        "# Permutation entropy\n",
        "print(ant.perm_entropy(x, normalize=True))\n",
        "# Spectral entropy\n",
        "print(ant.spectral_entropy(x, sf=100, method='welch', normalize=True))\n",
        "# Singular value decomposition entropy\n",
        "#print(ant.svd_entropy(x, normalize=True))\n",
        "# Approximate entropy\n",
        "#print(ant.app_entropy(x))\n",
        "# Sample entropy\n",
        "#print('sample entroy', ant.sample_entropy(x))\n",
        "# Hjorth mobility and complexity\n",
        "print(ant.hjorth_params(x))\n",
        "# Number of zero-crossings\n",
        "print(ant.num_zerocross(x))\n",
        "# Lempel-Ziv complexity\n",
        "print(ant.lziv_complexity('01111000011001', normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvEGJ4eQsGEJ"
      },
      "source": [
        "#sleep analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IAUaeitsm9w"
      },
      "outputs": [],
      "source": [
        "import yasa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load EEG data\n",
        "f = np.load('/content/data_full_6hrs_100Hz_Cz+Fz+Pz.npz')\n",
        "data, ch_names = f['data'], f['chan']\n",
        "sf = 100.\n",
        "\n",
        "# Load hypnogram\n",
        "hypno_30s = np.loadtxt('data_full_6hrs_100Hz_hypno_30s.txt')\n",
        "hypno = yasa.hypno_upsample_to_data(hypno=hypno_30s, sf_hypno=(1/30), data=data, sf_data=sf)\n",
        "print(hypno.shape, 'Unique values =', np.unique(hypno))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqLnjJfTrVWq"
      },
      "outputs": [],
      "source": [
        "#contruct yasa and mne array\n",
        "\n",
        "# sampling_freq = 200  # in Hertz\n",
        "# n_channels = 32\n",
        "# info = mne.create_info(n_channels, sfreq=sampling_freq)\n",
        "# print(info)\n",
        "\n",
        "# data = np.array([sine, cosine])\n",
        "\n",
        "# info = mne.create_info(ch_names=['10 Hz sine', '5 Hz cosine'],\n",
        "#                        ch_types=['misc'] * 2,\n",
        "#                        sfreq=sampling_freq)\n",
        "\n",
        "\n",
        "n_channels = 1\n",
        "sampling_freq = 2  # in Hertz\n",
        "info = mne.create_info(n_channels, sfreq=sampling_freq)\n",
        "print(info)\n",
        "\n",
        "\n",
        "data = np.array(df['RAW_AF8'].to_list())\n",
        "\n",
        "data = np.atleast_2d(data)\n",
        "\n",
        "info = mne.create_info(ch_names=['rawf8'],\n",
        "                        ch_types=['eeg'],\n",
        "                        sfreq=sampling_freq)\n",
        "\n",
        "simulated_raw = mne.io.RawArray(data, info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQSS_pXfx0Vc"
      },
      "outputs": [],
      "source": [
        "print(simulated_raw._data[0,0:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jox2yXWjr22t"
      },
      "outputs": [],
      "source": [
        "df.columns\n",
        "#'RAW_TP9', 'RAW_AF7', 'RAW_AF8', 'RAW_TP10'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uL73vaL0rNrz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcUEy8h5IECg"
      },
      "source": [
        "## filtering raw data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q_aGo5DIECi"
      },
      "outputs": [],
      "source": [
        "#!pip install mne\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import seaborn as sns\n",
        "# import mne\n",
        "#urlsleep = 'https://www.dropbox.com/s/hu50afgorep21c6/mindMonitor_2023-04-03--01-28-07_sleep.csv?dl=1'\n",
        "#dfraw = pd.read_csv('/content/mindMonitor_2023-01-18--14-37-14.csv')\n",
        "\n",
        "#dfraw = pd.read_csv('/content/mindMonitor_2023-02-15--14-48-03_stiumant_limited_interventions.csv')\n",
        "#dfraw = pd.read_csv('/content/mindMonitor_2023-02-23--08-01-50_eyesopen_eyesclose_mantrameditation_eyesopen_eyesclosed.csv')\n",
        "#dfraw = pd.read_csv('/content/mindMonitor_2023-02-23--08-01-50_eyesopen_eyesclose_mantrameditation_eyesopen_eyesclosed.csv')\n",
        "#urlsleep58 = 'https://www.dropbox.com/s/9r516639sms98sj/mindMonitor_2023-05-07--23-31-37_5188390995226691787_sleep.csv?dl=1'\n",
        "dfraw = pd.read_csv(urlsleep615)\n",
        "\n",
        "\n",
        "df = dfraw"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.TimeStamp.min())\n",
        "print(df.TimeStamp.max())"
      ],
      "metadata": {
        "id": "recIG4mAyRhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import mne\n",
        "import numpy as np\n",
        "\n",
        "# Get the RAW_AF8 column\n",
        "raw_af8 = df['RAW_AF8'].values\n",
        "\n",
        "# Convert the data to a floating-point type\n",
        "raw_af8 = raw_af8.astype(float)\n",
        "\n",
        "# Interpolate missing values\n",
        "raw_af8_interp = np.interp(np.arange(len(raw_af8)), np.where(~np.isnan(raw_af8))[0], raw_af8[~np.isnan(raw_af8)])\n",
        "\n",
        "# Define the filter parameters\n",
        "order = 3  # Filter order\n",
        "ftype = 'butter'  # Filter type\n",
        "\n",
        "# Specify the cutoff frequency\n",
        "f_p = 40.0  # Upper cutoff frequency (Hz)\n",
        "f_s = 1.0  # Lower cutoff frequency (Hz)\n",
        "\n",
        "# Set the sampling frequency\n",
        "sfreq = 256.0  # Sampling frequency (Hz)\n",
        "\n",
        "# Create the filter\n",
        "iir_params = dict(order=order, ftype=ftype)\n",
        "filt = mne.filter.create_filter(raw_af8_interp, sfreq, l_freq=f_s, h_freq=f_p, method=\"iir\", iir_params=iir_params, verbose=True)\n",
        "\n",
        "# Apply the filter to the data\n",
        "filtered_af8 = mne.filter.filter_data(raw_af8_interp, sfreq, l_freq=f_s, h_freq=f_p, method=\"iir\", iir_params=iir_params)\n",
        "\n",
        "# Check the filtered data range\n",
        "print(\"Filtered Data Range:\")\n",
        "print(\"Minimum value:\", min(filtered_af8))\n",
        "print(\"Maximum value:\", max(filtered_af8))\n",
        "\n",
        "df['filtered_AF8'] = filtered_af8"
      ],
      "metadata": {
        "id": "L7KoAQa8yeRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(figsize=(30, 3))\n",
        "sns.lineplot(data=df.iloc[260800:268480], x='TimeStamp', y='filtered_AF8')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JLc-lenunexJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0elm4gTwIEC5"
      },
      "outputs": [],
      "source": [
        "# Get the time stamp column\n",
        "time_stamps = np.array(df['TimeStamp'])\n",
        "\n",
        "# Get the RAW_AF8 column\n",
        "raw_af8 = df['RAW_AF8'].values\n",
        "raw_af7 = df['RAW_AF7'].values\n",
        "\n",
        "# Convert the data to a floating-point type\n",
        "raw_af8 = raw_af8.astype(np.float64)\n",
        "raw_af7 = raw_af7.astype(np.float64)\n",
        "\n",
        "# Ensure the conversion has been successful\n",
        "assert raw_af8.dtype == np.float64, f\"Unexpected data type: {raw_af8.dtype}\"\n",
        "assert raw_af7.dtype == np.float64, f\"Unexpected data type: {raw_af7.dtype}\"\n",
        "\n",
        "print(raw_af8.dtype)\n",
        "print(raw_af7.dtype)\n",
        "\n",
        "# Create a high-pass filter at 2 Hz and a low-pass filter at 45 Hz\n",
        "l_freq = 3.5\n",
        "h_freq = 8.5\n",
        "sfreq = 256.0  # explicitly defined as float\n",
        "\n",
        "# Apply the filter to the data\n",
        "filtered_af8 = mne.filter.filter_data(raw_af8, sfreq, l_freq=l_freq, h_freq=h_freq, fir_design='firwin')\n",
        "filtered_af7 = mne.filter.filter_data(raw_af7, sfreq, l_freq=l_freq, h_freq=h_freq, fir_design='firwin')\n",
        "\n",
        "# Create a new column in the DataFrame for filtered values\n",
        "df['filtered_AF8'] = filtered_af8\n",
        "df['filtered_AF7'] = filtered_af7\n",
        "\n",
        "# Calculate the average of filtered values and create a new column \"frontfil\"\n",
        "df['frontfil'] = (df['filtered_AF8'] + df['filtered_AF7']) / 2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the time stamp column\n",
        "time_stamps = np.array(df['TimeStamp'])\n",
        "\n",
        "# Get the RAW_AF8 and RAW_AF7 columns\n",
        "raw_af8 = df['RAW_AF8'].values\n",
        "raw_af7 = df['RAW_AF7'].values\n",
        "\n",
        "# Convert the data to a floating-point type\n",
        "raw_af8 = raw_af8.astype(np.float64)\n",
        "raw_af7 = raw_af7.astype(np.float64)\n",
        "\n",
        "# Ensure the conversion has been successful\n",
        "assert raw_af8.dtype == np.float64, f\"Unexpected data type: {raw_af8.dtype}\"\n",
        "assert raw_af7.dtype == np.float64, f\"Unexpected data type: {raw_af7.dtype}\"\n",
        "\n",
        "print(raw_af8.dtype)\n",
        "print(raw_af7.dtype)\n",
        "\n",
        "# Sampling frequency\n",
        "sfreq = 256.0  # explicitly defined as float\n",
        "\n",
        "# Slow wave sleep frequency range\n",
        "l_freq_slow = 0\n",
        "h_freq_slow = 4.5\n",
        "\n",
        "# N2 sleep frequency range\n",
        "l_freq_n2 = 4.6\n",
        "h_freq_n2 = 8.6\n",
        "\n",
        "# Apply the slow wave sleep filter to the data\n",
        "filtered_af8_slow = mne.filter.filter_data(raw_af8, sfreq, l_freq=l_freq_slow, h_freq=h_freq_slow, fir_design='firwin')\n",
        "filtered_af7_slow = mne.filter.filter_data(raw_af7, sfreq, l_freq=l_freq_slow, h_freq=h_freq_slow, fir_design='firwin')\n",
        "\n",
        "# Apply the N2 sleep filter to the data\n",
        "filtered_af8_n2 = mne.filter.filter_data(raw_af8, sfreq, l_freq=l_freq_n2, h_freq=h_freq_n2, fir_design='firwin')\n",
        "filtered_af7_n2 = mne.filter.filter_data(raw_af7, sfreq, l_freq=l_freq_n2, h_freq=h_freq_n2, fir_design='firwin')\n",
        "\n",
        "# Create new columns in the DataFrame for filtered values\n",
        "df['filtered_AF8_slow'] = filtered_af8_slow\n",
        "df['filtered_AF7_slow'] = filtered_af7_slow\n",
        "df['filtered_AF8_n2'] = filtered_af8_n2\n",
        "df['filtered_AF7_n2'] = filtered_af7_n2\n",
        "\n",
        "# Calculate the average of filtered values for each band and create new columns\n",
        "df['frontfil_slow'] = (df['filtered_AF8_slow'] + df['filtered_AF7_slow']) / 2\n",
        "df['frontfil_n2'] = (df['filtered_AF8_n2'] + df['filtered_AF7_n2']) / 2\n"
      ],
      "metadata": {
        "id": "csEvOTa3z0q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## graph large with datashader"
      ],
      "metadata": {
        "id": "TIY-0F15xJnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datashader as ds\n",
        "import datashader.transfer_functions as tf\n",
        "from IPython.display import display\n",
        "\n",
        "# Total number of rows to plot\n",
        "total_rows = 460800\n",
        "\n",
        "# Rows per plot\n",
        "chunk_size = 7680\n",
        "\n",
        "# Number of chunks to plot\n",
        "n_chunks = total_rows // chunk_size\n",
        "\n",
        "for i in range(n_chunks):\n",
        "    start_row = i * chunk_size\n",
        "    end_row = start_row + chunk_size - 1  # Subtract 1 since end_row is inclusive\n",
        "\n",
        "    # Get the timestamp for the start and end rows\n",
        "    start_time = df.iloc[start_row]['TimeStamp']\n",
        "    end_time = df.iloc[end_row]['TimeStamp']\n",
        "    print(f\"Plotting from {start_time} to {end_time}\")\n",
        "\n",
        "    # Slice the DataFrame to include only the current chunk of rows\n",
        "    df_chunk = df.iloc[start_row:end_row+1].copy()  # Create a copy to avoid modifying original data\n",
        "\n",
        "    # Convert datetime index to numerical representation (seconds since 1970-01-01)\n",
        "    df_chunk['time_numeric'] = df_chunk.index.astype(int) / 10**9\n",
        "\n",
        "    # Create the datashader canvas\n",
        "    canvas = ds.Canvas(plot_width=1500, plot_height=300)\n",
        "\n",
        "    # Aggregate the data (binning into pixels)\n",
        "    agg = canvas.line(df_chunk, 'time_numeric', 'filtered_AF8')\n",
        "\n",
        "    # Transform the aggregated data into an image\n",
        "    img = tf.shade(agg)\n",
        "\n",
        "    # Display the image\n",
        "    display(img)\n"
      ],
      "metadata": {
        "id": "FDWiG5FXxMmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datashader as ds\n",
        "import datashader.transfer_functions as tf\n",
        "from colorcet import fire, bgy\n",
        "\n",
        "# Total number of rows to plot\n",
        "total_rows = 460800\n",
        "\n",
        "# Rows per plot\n",
        "chunk_size = 7680\n",
        "\n",
        "# Number of chunks to plot\n",
        "n_chunks = total_rows // chunk_size\n",
        "\n",
        "\n",
        "for i in range(n_chunks):\n",
        "    start_row = i * chunk_size\n",
        "    end_row = start_row + chunk_size\n",
        "    print(f\"Plotting rows {start_row} to {end_row}\")\n",
        "\n",
        "    # Slice the DataFrame to include only the current chunk of rows\n",
        "    df_chunk = df.iloc[start_row:end_row].copy()  # Create a copy to avoid modifying original data\n",
        "\n",
        "    # Convert datetime index to numerical representation (seconds since 1970-01-01)\n",
        "    df_chunk['TimeStamp'] = pd.to_datetime(df_chunk['TimeStamp'])\n",
        "\n",
        "    df_chunk['time_numeric'] = df_chunk['TimeStamp'].astype(int) / 10**9\n",
        "\n",
        "    # Create the datashader canvas\n",
        "    canvas = ds.Canvas(plot_width=1500, plot_height=300)\n",
        "\n",
        "    # Aggregate the data (binning into pixels)\n",
        "    agg_slow = canvas.line(df_chunk, 'time_numeric', 'frontfil_slow')\n",
        "    agg_n2 = canvas.line(df_chunk, 'time_numeric', 'frontfil_n2')\n",
        "\n",
        "    # Transform the aggregated data into images\n",
        "    img_slow = tf.shade(agg_slow, cmap=fire)\n",
        "    img_n2 = tf.shade(agg_n2, cmap=bgy)\n",
        "\n",
        "    # Overlay the two images\n",
        "    img_overlay = tf.stack(img_slow, img_n2)\n",
        "\n",
        "    # Display the image\n",
        "    display(img_overlay)\n"
      ],
      "metadata": {
        "id": "EZzC_Cp-4d9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sleep 614\n",
        "\n",
        "sleep 614 deep sleep at around 10:04 pm and REM at around 1am\n"
      ],
      "metadata": {
        "id": "d5qMdVKRKqFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfraw = pd.read_csv(urlsleep614)\n",
        "\n",
        "df = dfraw\n"
      ],
      "metadata": {
        "id": "HMdr5ax4Kg8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "print (df.TimeStamp.max())\n",
        "print (df.TimeStamp.min())"
      ],
      "metadata": {
        "id": "xaudDOPfLUVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['time'] = pd.to_datetime(df['TimeStamp'])\n",
        "\n"
      ],
      "metadata": {
        "id": "tvftCt8RLels"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create new DataFrame with 'time' as the index\n",
        "dft = df.set_index('time')\n",
        "\n",
        "# Slice the DataFrame between 6:30 AM and 7:00 AM\n",
        "dft_sliced = dft.between_time('02:30', '03:00')\n",
        "\n",
        "dft_30s = dft_sliced.iloc[:7680].reset_index()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.lineplot(x='time', y='RAW_AF8', data=dft_30s) #first 30 seconds\n",
        "plt.title('RAW_AF8 Line Plot for the First 30 Seconds')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "IAwlc6q_MotD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#attempt filtered\n",
        "\n",
        "# Get the RAW_AF8 column\n",
        "raw_af8 = dft_30s['RAW_AF8'].values\n",
        "\n",
        "# Convert the data to a floating-point type\n",
        "raw_af8 = raw_af8.astype(np.float64)\n",
        "\n",
        "# Ensure the conversion has been successful\n",
        "assert raw_af8.dtype == np.float64, f\"Unexpected data type: {raw_af8.dtype}\"\n",
        "\n",
        "print(raw_af8.dtype)\n",
        "\n",
        "# Create a high-pass filter at 0.1 Hz\n",
        "sfreq = 256.0  # explicitly defined as float\n",
        "\n",
        "# Apply the filter to the data\n",
        "filtered_data = mne.filter.filter_data(raw_af8, sfreq, l_freq=0.5, h_freq=None, fir_design='firwin')\n",
        "\n",
        "# Create a new column in the DataFrame\n",
        "dft_30s['f8f'] = filtered_data\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.lineplot(x='time', y='f8f', data=dft_30s) #first 30 seconds\n",
        "plt.title('filtered RAW_AF8 Line Plot for the First 30 Seconds')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mk13x9AeOq1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dft_30s.head()"
      ],
      "metadata": {
        "id": "ASzFRjMVPh1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leSRApDQp-z_"
      },
      "source": [
        "##large sleep section imported from git\n",
        "\n",
        "for now, load sleep files manually. not working from url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYHif5pPqDVS"
      },
      "outputs": [],
      "source": [
        "#!pip install mne\n",
        "#!pip install yasa\n",
        "import pandas as pd\n",
        "import mne\n",
        "import numpy as np\n",
        "import yasa\n",
        "\n",
        "#urlsleep58 = 'https://www.dropbox.com/s/9r516639sms98sj/mindMonitor_2023-05-07--23-31-37_5188390995226691787_sleep.csv?dl=1'\n",
        "#urlnap58 = 'https://www.dropbox.com/s/fbjsqhjlhuocps4/mindMonitor_2023-05-08--14-47-48_7822430682462145648_nap.csv?dl=1'\n",
        "#dfraw = pd.read_csv(urlnap58, skiprows=[169541, 202609])\n",
        "#dfs = dfraw[['RAW_AF8']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIO1OPOA5S7y"
      },
      "outputs": [],
      "source": [
        "# import urllib.request\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# urlnap58 = 'https://www.dropbox.com/s/fbjsqhjlhuocps4/mindMonitor_2023-05-08--14-47-48_7822430682462145648_nap.csv?dl=1'\n",
        "# # Download the file with a progress bar\n",
        "\n",
        "# with urllib.request.urlopen(urlnap58) as response:\n",
        "#     sleepfile = response.read().decode(\"utf-8\")\n",
        "\n",
        "# # Save the file to Colab memory\n",
        "# with open(\"sleepfile.csv\", \"w\") as f:\n",
        "#     f.write(sleepfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOz8rBwZJH1o"
      },
      "outputs": [],
      "source": [
        "#manually loaded\n",
        "df = pd.read_csv('/content/mindMonitor_2023-05-08--14-47-48_7822430682462145648_nap (2).csv', error_bad_lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0itv8c4KaU1"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "127rn6DkLCNx"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b64mZw_LgYb"
      },
      "outputs": [],
      "source": [
        "df.head(300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFB_K7OcLWNi"
      },
      "outputs": [],
      "source": [
        "df[\"time\"] = pd.to_datetime(df[\"TimeStamp\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBqU05ygOl1h"
      },
      "outputs": [],
      "source": [
        "df['RAW_AF8'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epmgsBEdLEnH"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Get the time periods\n",
        "#start_time = 2023-05-08 14:47:48.254\n",
        "#end_time = 2023-05-08 14:49:48.254\n",
        "\n",
        "# Filter the dataframe to the specified time periods\n",
        "#df = df[(df['timestamp'] > start_time) & (df['timestamp'] < end_time)]\n",
        "\n",
        "# Create a line plot of the 'RAW_AF8' column, with the x-axis in seconds\n",
        "#sns.lineplot(x=df['time'].dt.second, y='RAW_AF8', data=df)\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "sns.lineplot(x=df['time'], y='RAW_AF7', data=df.sample(100))\n",
        "ax.set_ylim(750, 850)\n",
        "\n",
        "\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuONOvE3qMF0"
      },
      "outputs": [],
      "source": [
        "dfs = dfraw[['RAW_AF8']]\n",
        "\n",
        "def df_to_raw(df):\n",
        "    raw = np.array(df)\n",
        "    return raw\n",
        "\n",
        "# changes: Set 'sfreq' to the minimum 81\n",
        "# When it comes to electrophysiological data, MNE works on the basis of samples, not time points\n",
        "# The duration of the recording can then be calculated by dividing the number of samples by the sampling frequency\n",
        "# Using data from urlspeep: samples/frequency -> 35720/256 = 139.531 seconds\n",
        "# OpenAI Prompt:\n",
        "#   # The duration of recording of a mne object\n",
        "def raw_to_mne(raw):\n",
        "    info = mne.create_info(ch_names=['RAW_AF8'],\n",
        "                           sfreq=256,\n",
        "                           ch_types=['eeg'])\n",
        "    mne_raw = mne.io.RawArray(raw, info)\n",
        "    return mne_raw\n",
        "\n",
        "# Turns the MNE object into the YASA package\n",
        "def mne_to_yasa(mne_raw):\n",
        "    yasa_raw = yasa.SleepStaging(mne_raw, eeg_name='RAW_AF8')\n",
        "    return yasa_raw\n",
        "\n",
        "# Initialize the sleep staging instance\n",
        "sls = mne_to_yasa(raw_to_mne(df_to_raw(dfs.values.T)))\n",
        "\n",
        "# Get the predicted sleep stages\n",
        "hypno = sls.predict()\n",
        "# Get the predicted probabilities\n",
        "proba = sls.predict_proba()\n",
        "# Get the confidence\n",
        "confidence = proba.max(axis=1)\n",
        "# Plot the predicted probabilities\n",
        "sls.plot_predict_proba()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AsxNYWp9P-Zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Audio and breath analysis"
      ],
      "metadata": {
        "id": "uP6jhkWSP_bf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pt_YUlmLQBdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import requests\n",
        "\n",
        "def download_file_from_dropbox(url, filename):\n",
        "    response = requests.get(url, stream=True)\n",
        "    with io.open(filename, \"wb\") as f:\n",
        "        for chunk in response.iter_content(chunk_size=1024):\n",
        "            f.write(chunk)\n",
        "\n",
        "url = urlaudiobreathsleep71623\n",
        "\n",
        "filename = \"file.mp3\"\n",
        "download_file_from_dropbox(url, filename)\n",
        "\n"
      ],
      "metadata": {
        "id": "PMJJwyt2fn2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the audio file\n",
        "#audio_path = '/content/breathing_example.m4a'\n",
        "audio, sr = librosa.load('/content/file.mp3')\n",
        "\n",
        "# Compute the spectrogram\n",
        "spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
        "\n",
        "# Convert to dB scale\n",
        "spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
        "\n",
        "# Plot the spectrogram with the suggested color palette\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(spectrogram_db, sr=sr, x_axis='time', y_axis='mel', cmap='viridis')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('Spectrogram')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7bHtTkyBnJgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load muse file for short breathing test\n",
        "dfraw = pd.read_csv(urlbreathingshorttestmuse)\n",
        "df = dfraw"
      ],
      "metadata": {
        "id": "az_6zBn3oWul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "YsaLUFeFqCuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from scipy.signal import butter, lfilter\n",
        "\n",
        "# Load the entire audio file\n",
        "audio_path = '/content/breathing_example.m4a'\n",
        "audio_full, sr = librosa.load(audio_path)\n",
        "\n",
        "# Compute the spectrogram\n",
        "spectrogram = librosa.feature.melspectrogram(y=audio_full, sr=sr)\n",
        "\n",
        "# Convert to dB scale\n",
        "spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
        "\n",
        "#new dataframe\n",
        "dfs = df.dropna(subset=['PPG_IR'])\n",
        "\n",
        "# Convert 'TimeStamp' column to datetime\n",
        "dfs['TimeStamp'] = pd.to_datetime(df['TimeStamp'])\n",
        "\n",
        "#frequency\n",
        "fs = 256.0  # Sampling frequency\n",
        "lowcut = 0.4  # Low cutoff frequency\n",
        "highcut = 4.0  # High cutoff frequency\n",
        "nyq = 0.5 * fs  # Nyquist frequency\n",
        "low = lowcut / nyq\n",
        "high = highcut / nyq\n",
        "b, a = butter(3, [low, high], btype='band')\n",
        "\n",
        "# Apply Butterworth filter\n",
        "dfs['filtered_PPG_IR'] = lfilter(b, a, dfs['PPG_IR'].values)\n",
        "\n",
        "# Create two subplots: one for the unfiltered PPG data, one for the filtered PPG data\n",
        "fig, ax = plt.subplots(2, 1, figsize=(10, 8))\n",
        "\n",
        "# Plot the unfiltered PPG data\n",
        "sns.lineplot(data=dfs[::2], x='TimeStamp', y=\"PPG_IR\", ax=ax[0])\n",
        "ax[0].set(xlabel='TimeStamp', ylabel='Unfiltered PPG_IR')\n",
        "\n",
        "# Plot the filtered PPG data\n",
        "sns.lineplot(data=dfs[::2], x='TimeStamp', y=\"filtered_PPG_IR\", ax=ax[1])\n",
        "ax[1].set(xlabel='TimeStamp', ylabel='Filtered PPG_IR')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "import IPython.display as ipd\n",
        "ipd.Audio(audio_path, rate=sr)\n"
      ],
      "metadata": {
        "id": "qyBQtmhJoqAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dfs['PPG_IR'].isna().sum())\n",
        "print (len(dfs['PPG_IR']))\n",
        "\n",
        "dfs = dfs.dropna(subset=['PPG_IR'])\n",
        "\n",
        "\n",
        "# Butterworth bandpass filter design\n",
        "fs = 256.0  # Sampling frequency\n",
        "lowcut = 0.5  # Low cutoff frequency\n",
        "highcut = 3.0  # High cutoff frequency\n",
        "nyq = 0.5 * fs  # Nyquist frequency\n",
        "low = lowcut / nyq\n",
        "high = highcut / nyq\n",
        "b, a = butter(2, [low, high], btype='band')\n",
        "\n",
        "# Apply the filter\n",
        "dfs['PPG_IR_Filtered'] = filtfilt(b, a, dfs['PPG_IR'])\n",
        "\n",
        "dfs['PPG_IR_Filtered'].describe()\n",
        "\n"
      ],
      "metadata": {
        "id": "xxsm-h5faB6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ECG data"
      ],
      "metadata": {
        "id": "dvm_6GRVyRBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the txt file\n",
        "with open(\"/content/2023-04-12 11-56-41.txt\", \"r\") as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "# Remove the \\n character from each line\n",
        "lines = [line.strip(\"\\n\") for line in lines]\n",
        "\n",
        "# Convert the lines to integers\n",
        "lines = [int(line) for line in lines]\n",
        "\n",
        "# Create a Pandas DataFrame\n",
        "dfg = pd.DataFrame(lines, columns=[\"data\"])\n",
        "\n",
        "# Print the DataFrame\n",
        "print(dfg)\n"
      ],
      "metadata": {
        "id": "MC-8NHuty4rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lineplot(data=dfg[0:1000], x=dfg.index[:1000], y='data')\n"
      ],
      "metadata": {
        "id": "TfHpVjoM0KFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#status\n",
        "\n",
        "add time stamps to polar EMC\n",
        "\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "# Get the name of the text file\n",
        "filename = \"2023-04-12 11-56-41\"\n",
        "\n",
        "# Get the timestamp\n",
        "timestamp = datetime.datetime.strptime(filename, \"%Y-%m-%d %H-%M-%S\")\n",
        "\n",
        "# Open the text file\n",
        "with open(filename, \"r\") as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "# Add the timestamp to the lines\n",
        "for i, line in enumerate(lines):\n",
        "  new_line = \"%s, %.3f\" % (timestamp + timedelta(seconds=i / 130), line)\n",
        "  lines[i] = new_line\n",
        "\n",
        "# Save the text file\n",
        "with open(filename, \"w\") as f:\n",
        "  f.writelines(lines)\n"
      ],
      "metadata": {
        "id": "LRJox4pTwstw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#upwork notebook"
      ],
      "metadata": {
        "id": "nGg0Zo-R97zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import mne\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from openpyxl import load_workbook\n",
        "import ipywidgets as widgets\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "\n",
        "#function\n",
        "\n",
        "different_frequency_bands = 0\n",
        "def plot_sleep_EEG(epoch, ch_names, data_epoch, time_epoch, fig_title):\n",
        "    fig, ax = plt.subplots(figsize=(20, 10))\n",
        "    ylimit = 50\n",
        "    shift_y = 500\n",
        "    for i in range(data_epoch.shape[0]):\n",
        "        shift = i * shift_y\n",
        "        ax.plot(time_epoch, data_epoch[i, :] + shift)\n",
        "        (_, caps, _) = ax.errorbar(x=time_epoch[0], y=shift,\n",
        "                                   yerr=ylimit, color='k', capsize=5)\n",
        "        for cap in caps:\n",
        "            cap.set_markeredgewidth(1)\n",
        "        # *2 because it goes from -ylimit to +ylimit\n",
        "        ax.text(x=time_epoch[0]-0.5, y=shift,\n",
        "                s=str(ylimit*2)+'V', ha='center')\n",
        "\n",
        "    y_ticks = np.arange(data_epoch.shape[0]) * shift_y\n",
        "    ax.set_yticks(y_ticks)\n",
        "    ax.set_yticklabels(ch_names)\n",
        "\n",
        "    ax.set_xlabel('Time (sec)')\n",
        "    ax.set_title('Epoch number:' + str(epoch+1) + ', ' + fig_title)\n",
        "    pdf.savefig(fig)\n",
        "\n",
        "def handle_text_submit(sender):\n",
        "    epoch = int(sender.value)\n",
        "    print('-'*300)\n",
        "    print('Epoch number:', epoch)\n",
        "    epoch_length = (epoch-1)*30*sfreq\n",
        "    epoch_samples = [epoch_length, (epoch_length) +\n",
        "                    sfreq*30]  # 30-second epoch\n",
        "    if (epoch_samples[1] > hold_data.shape[1]):\n",
        "        raise Exception(\n",
        "            'This epoch exceeds the length of the available data, please try again with a smaller value')\n",
        "\n",
        "    data_epoch = hold_data[:, epoch_samples[0]:epoch_samples[1]]\n",
        "    time_epoch = raw.times[epoch_samples[0]:epoch_samples[1]]\n",
        "    plot_sleep_EEG(epoch, ch_names, data_epoch, time_epoch, 'Broad')\n",
        "\n",
        "    if different_frequency_bands==1:\n",
        "      # looking at specific frequency bands\n",
        "      data_epoch = raw_delta.get_data()[:, epoch_samples[0]:epoch_samples[1]]\n",
        "      plot_sleep_EEG(epoch, ch_names, data_epoch, time_epoch, 'Delta')\n",
        "\n",
        "      data_epoch = raw_theta.get_data()[:, epoch_samples[0]:epoch_samples[1]]\n",
        "      plot_sleep_EEG(epoch, ch_names, data_epoch, time_epoch, 'Theta')\n",
        "\n",
        "      data_epoch = raw_alpha.get_data()[:, epoch_samples[0]:epoch_samples[1]]\n",
        "      plot_sleep_EEG(epoch, ch_names, data_epoch, time_epoch, 'Alpha')\n",
        "\n",
        "      data_epoch = raw_sigma.get_data()[:, epoch_samples[0]:epoch_samples[1]]\n",
        "      plot_sleep_EEG(epoch, ch_names, data_epoch, time_epoch, 'Sigma')\n",
        "    plt.show()\n",
        "    sender.value = ''\n",
        "\n",
        "##load data\n",
        "#loc = 'https://www.dropbox.com/s/q37nqho2xmprdgz/mindMonitor_2023-06-15--00-27-29_8457076698113972093.csv?dl=1'\n",
        "loc = urlsleep721\n",
        "dfraw = pd.read_csv(loc)\n",
        "df = dfraw\n",
        "\n",
        "\n",
        "raw_data = df.loc[1:, ['RAW_TP9', 'RAW_AF7', 'RAW_AF8', 'RAW_TP10']]\n",
        "\n",
        "# dropping missing values\n",
        "raw_data = raw_data.dropna(\n",
        "    subset=['RAW_TP9', 'RAW_AF7', 'RAW_AF8', 'RAW_TP10'])\n",
        "\n",
        "raw_data = raw_data[:].values\n",
        "\n",
        "\n",
        "##preprocessing\n",
        "\n",
        "sfreq = 256\n",
        "ch_types = [\"eeg\"]*raw_data.shape[1]\n",
        "ch_names = [\"TP9\", \"AF7\", \"AF8\", \"TP10\"]\n",
        "montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
        "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
        "samples = raw_data.T\n",
        "\n",
        "# checking that there are no missing values\n",
        "np.sum((np.isnan((samples[0, :]))) + 0)\n",
        "\n",
        "# demean\n",
        "# samples = samples - np.mean(samples, axis=1)[:, np.newaxis]\n",
        "# common average reference\n",
        "# get the mean across channels and then we repeat this to match the data and then subtract it from the data\n",
        "# samples = samples - \\\n",
        "#     np.repeat(np.mean(samples, axis=0)[\n",
        "#               np.newaxis, :], samples.shape[0], axis=0)\n",
        "# TP9 and TP10 as reference\n",
        "# samples = samples - \\\n",
        "#     np.repeat(np.mean(np.vstack((samples[0, :], samples[3, :])), axis=0)[\n",
        "#               np.newaxis, :], samples.shape[0], axis=0)\n",
        "\n",
        "raw = mne.io.RawArray(samples, info)\n",
        "\n",
        "\n",
        "# raw = raw.copy().notch_filter(freqs=[50])\n",
        "# raw = raw.copy().resample(100, npad='auto')\n",
        "# raw = raw.copy().filter(l_freq=0.5, h_freq=15)\n",
        "# if different_frequency_bands==1:\n",
        "#   raw_delta = raw.copy().filter(l_freq=0.1, h_freq=4)\n",
        "#   raw_theta = raw.copy().filter(l_freq=4, h_freq=8)\n",
        "#   raw_alpha = raw.copy().filter(l_freq=8, h_freq=12)\n",
        "#   raw_sigma = raw.copy().filter(l_freq=11, h_freq=16)  # for spindles\n",
        "#sfreq = 100\n",
        "\n",
        "##preprocess with butterworth edited\n",
        "\n",
        "sfreq = 256\n",
        "ch_types = [\"eeg\"]*raw_data.shape[1]\n",
        "ch_names = [\"TP9\", \"AF7\", \"AF8\", \"TP10\"]\n",
        "montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
        "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
        "samples = raw_data.T\n",
        "\n",
        "# checking that there are no missing values\n",
        "np.sum((np.isnan((samples[0, :]))) + 0)\n",
        "\n",
        "# demean\n",
        "# samples = samples - np.mean(samples, axis=1)[:, np.newaxis]\n",
        "# common average reference\n",
        "# get the mean across channels and then we repeat this to match the data and then subtract it from the data\n",
        "# samples = samples - \\\n",
        "#     np.repeat(np.mean(samples, axis=0)[\n",
        "#               np.newaxis, :], samples.shape[0], axis=0)\n",
        "# TP9 and TP10 as reference\n",
        "# samples = samples - \\\n",
        "#     np.repeat(np.mean(np.vstack((samples[0, :], samples[3, :])), axis=0)[\n",
        "#               np.newaxis, :], samples.shape[0], axis=0)\n",
        "\n",
        "raw = mne.io.RawArray(samples, info)\n",
        "\n",
        "# applying the bandpass Butterworth filter\n",
        "raw = raw.copy().filter(l_freq=0.5, h_freq=40, method='iir', iir_params={\"order\": 4, \"ftype\": \"butter\"})\n",
        "#raw = raw.copy().resample(100, npad='auto')\n",
        "\n",
        "# if different_frequency_bands==1:\n",
        "#   raw_delta = raw.copy().filter(l_freq=0.1, h_freq=4)\n",
        "#   raw_theta = raw.copy().filter(l_freq=4, h_freq=8)\n",
        "#   raw_alpha = raw.copy().filter(l_freq=8, h_freq=12)\n",
        "#   raw_sigma = raw.copy().filter(l_freq=11, h_freq=16)  # for spindles\n",
        "#sfreq = 100\n",
        "\n",
        "##display continuous data\n",
        "\n",
        "hold_data = (raw.get_data())\n",
        "\n",
        "fig = plt.figure(figsize=(20, 15))\n",
        "plt.plot(raw.times[:510*30*256], hold_data[:, :510*30*256].T)\n",
        "plt.xlabel(\"Time (sec)\")\n",
        "plt.ylabel(\"Amplitude (uV)\")\n",
        "plt.title(\"raw data\")\n",
        "plt.show()\n",
        "\n",
        "##call functions and display\n",
        "\n",
        "print('max epoch is: ' + str(int(np.floor((hold_data.shape[1]/(30*sfreq))))))\n",
        "# textbox = widgets.Text(placeholder='Please enter the epoch number')\n",
        "# textbox.on_submit(handle_text_submit)\n",
        "pdf = PdfPages('Output figures.pdf')\n",
        "\n",
        "for epoch in range(int(np.floor((hold_data.shape[1]/(30*sfreq)))) ):\n",
        "  print('Epoch number:', epoch+1)\n",
        "  epoch_length = (epoch)*30*sfreq\n",
        "  epoch_samples = [epoch_length, (epoch_length) +\n",
        "                  sfreq*30]  # 30-second epoch\n",
        "\n",
        "  data_epoch = hold_data[:, epoch_samples[0]:epoch_samples[1]]\n",
        "  time_epoch = raw.times[epoch_samples[0]:epoch_samples[1]]\n",
        "  plot_sleep_EEG(epoch, ch_names, data_epoch, time_epoch, 'Broad')\n",
        "\n",
        "  if different_frequency_bands==1:\n",
        "    # looking at specific frequency bands\n",
        "    data_epoch = raw_delta.get_data()[:, epoch_samples[0]:epoch_samples[1]]\n",
        "    plot_sleep_EEG(epoch, ch_names, data_epoch, time_epoch, 'Delta')\n",
        "\n",
        "    data_epoch = raw_theta.get_data()[:, epoch_samples[0]:epoch_samples[1]]\n",
        "    plot_sleep_EEG(epoch, ch_names, data_epoch, time_epoch, 'Theta')\n",
        "\n",
        "    data_epoch = raw_alpha.get_data()[:, epoch_samples[0]:epoch_samples[1]]\n",
        "    plot_sleep_EEG(epoch, ch_names, data_epoch, time_epoch, 'Alpha')\n",
        "\n",
        "    data_epoch = raw_sigma.get_data()[:, epoch_samples[0]:epoch_samples[1]]\n",
        "    plot_sleep_EEG(epoch, ch_names, data_epoch, time_epoch, 'Sigma')\n",
        "  plt.show()\n",
        "\n",
        "pdf.close()\n",
        "# display(textbox)\n"
      ],
      "metadata": {
        "id": "x9pyShhE97XS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##preprocess with butterworth edited\n",
        "\n",
        "sfreq = 256\n",
        "ch_types = [\"eeg\"]*raw_data.shape[1]\n",
        "ch_names = [\"TP9\", \"AF7\", \"AF8\", \"TP10\"]\n",
        "montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
        "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
        "samples = raw_data.T\n",
        "\n",
        "# checking that there are no missing values\n",
        "np.sum((np.isnan((samples[0, :]))) + 0)\n",
        "\n",
        "# demean\n",
        "# samples = samples - np.mean(samples, axis=1)[:, np.newaxis]\n",
        "# common average reference\n",
        "# get the mean across channels and then we repeat this to match the data and then subtract it from the data\n",
        "# samples = samples - \\\n",
        "#     np.repeat(np.mean(samples, axis=0)[\n",
        "#               np.newaxis, :], samples.shape[0], axis=0)\n",
        "# TP9 and TP10 as reference\n",
        "# samples = samples - \\\n",
        "#     np.repeat(np.mean(np.vstack((samples[0, :], samples[3, :])), axis=0)[\n",
        "#               np.newaxis, :], samples.shape[0], axis=0)\n",
        "\n",
        "raw = mne.io.RawArray(samples, info)\n",
        "\n",
        "# applying the bandpass Butterworth filter\n",
        "raw = raw.copy().filter(l_freq=0.1, h_freq=50, method='iir', iir_params={\"order\": 3, \"ftype\": \"butter\"})\n",
        "#raw = raw.copy().resample(100, npad='auto')\n",
        "\n",
        "if different_frequency_bands==1:\n",
        "  raw_delta = raw.copy().filter(l_freq=0.1, h_freq=4)\n",
        "  raw_theta = raw.copy().filter(l_freq=4, h_freq=8)\n",
        "  raw_alpha = raw.copy().filter(l_freq=8, h_freq=12)\n",
        "  raw_sigma = raw.copy().filter(l_freq=11, h_freq=16)  # for spindles\n",
        "#sfreq = 100\n",
        "\n",
        "##display continuous data\n",
        "\n",
        "hold_data = (raw.get_data())\n",
        "\n",
        "fig = plt.figure(figsize=(20, 15))\n",
        "plt.plot(raw.times[:510*30*256], hold_data[:, :510*30*256].T)\n",
        "plt.xlabel(\"Time (sec)\")\n",
        "plt.ylabel(\"Amplitude (uV)\")\n",
        "plt.title(\"raw data\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "86v1BJdXbhdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vovnG4CKMIrL"
      },
      "source": [
        "#Mock data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFGkjXHEMNET"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9AYmg_RSuWz"
      },
      "outputs": [],
      "source": [
        "#url = 'https://www.dropbox.com/s/z09umrre7qgg4ld/mindMonitor_2023-02-23--08-01-50_eyesopen_eyesclose_mantrameditation_eyesopen_eyesclosed.csv?dl=1'\n",
        "url = 'https://www.dropbox.com/s/a5uwkqaq71mkrxp/mindMonitor_2023-02-17--18-29-44_choc_intervention.csv?dl=1'\n",
        "#url = 'https://www.dropbox.com/s/pdin2ayuuybcpi0/mindMonitor_2023-02-22--08-57-17_mantra_meditation.csv?dl=1'\n",
        "#url = 'https://www.dropbox.com/s/uq60t8qy33i21dt/mindMonitor_2023-02-14--09-43-07_huberman_cyclic_breath_work.csv?dl=1'\n",
        "dfraw = pd.read_csv(url)\n",
        "\n",
        "dfraw.head()\n",
        "\n",
        "#df = dfraw[::256]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZBNLiMxfT9m"
      },
      "outputs": [],
      "source": [
        "dictionary = {'TimeStamp': {0: '2023-02-23 08:01:50.701',\n",
        "  1: '2023-02-23 08:01:50.798',\n",
        "  2: '2023-02-23 08:01:50.798',\n",
        "  3: '2023-02-23 08:01:50.800',\n",
        "  4: '2023-02-23 08:01:50.800'},\n",
        " 'Delta_TP9': {0: np.nan,\n",
        "  1: 0.8932789112449511,\n",
        "  2: 0.8932789112449511,\n",
        "  3: 0.8932789112449511,\n",
        "  4: 0.8932789112449511},\n",
        " 'Delta_AF7': {0: np.nan,\n",
        "  1: -0.062321571240896,\n",
        "  2: -0.0734485722420289,\n",
        "  3: -0.0734485722420289,\n",
        "  4: -0.0734485722420289}}\n",
        "\n",
        "dfm = pd.DataFrame.from_dict(dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NH69NC8bfVuD"
      },
      "outputs": [],
      "source": [
        "#contruct yasa and mne array\n",
        "\n",
        "# sampling_freq = 200  # in Hertz\n",
        "# n_channels = 32\n",
        "# info = mne.create_info(n_channels, sfreq=sampling_freq)\n",
        "# print(info)\n",
        "\n",
        "# data = np.array([sine, cosine])\n",
        "\n",
        "# info = mne.create_info(ch_names=['10 Hz sine', '5 Hz cosine'],\n",
        "#                        ch_types=['misc'] * 2,\n",
        "#                        sfreq=sampling_freq)\n",
        "\n",
        "\n",
        "n_channels = 1\n",
        "sampling_freq = 256  # in Hertz\n",
        "info = mne.create_info(n_channels, sfreq=sampling_freq)\n",
        "print(info)\n",
        "\n",
        "\n",
        "data = np.array(df['Delta_TP9'].to_list())\n",
        "\n",
        "data = np.atleast_2d(data)\n",
        "\n",
        "info = mne.create_info(ch_names=['rawf8'],\n",
        "                        ch_types=['eeg'],\n",
        "                        sfreq=sampling_freq)\n",
        "\n",
        "simulated_raw = mne.io.RawArray(data, info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkrghrrQYYCg"
      },
      "outputs": [],
      "source": [
        "## reduce file size\n",
        "\n",
        "df = (dfraw.select_dtypes('number')\n",
        "   .rolling(500, min_periods=1).mean()\n",
        "   .join(dfraw.select_dtypes(exclude='number'))\n",
        "   [dfraw.columns]\n",
        " )\n",
        "\n",
        "df = df[::256]\n",
        "\n",
        "print (len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2YQ5tqx5q0l"
      },
      "outputs": [],
      "source": [
        "\n",
        "df = (dfraw.select_dtypes('number')\n",
        "   .rolling(500, min_periods=1).mean()\n",
        "   .join(dfraw.select_dtypes(exclude='number'))\n",
        "   [dfraw.columns]\n",
        " )\n",
        "\n",
        "df = df[::500]\n",
        "\n",
        "print (len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-mByPAW8MZX"
      },
      "outputs": [],
      "source": [
        "#norming data and ratio\n",
        "\n",
        "df['Theta_AF8_norm'] = (df['Theta_AF8']-df['Theta_AF8'].min()) / ((df['Theta_AF8'].max()-df['Theta_AF8'].min()))\n",
        "df['Beta_AF8_norm'] = (df['Beta_AF8']-df['Beta_AF8'].min()) / ((df['Beta_AF8'].max()-df['Beta_AF8'].min()))\n",
        "df['ThetaBetaRatio_AF8_norm'] = df['Theta_AF8_norm'] / df['Beta_AF8_norm']\n",
        "\n",
        "df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzRx5R_1Dmdl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import seaborn.apionly as sns\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 8))\n",
        "\n",
        "ax = sns.lineplot(x='TimeStamp', y='ThetaBetaRatio_AF8_norm', data=df, ax=ax )\n",
        "\n",
        "#ax2 = sns.lineplot(x='TimeStamp', y='Gamma_AF8', data=dfraw, ax=ax)\n",
        "\n",
        "ax.set(ylim=(-1, 3))\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.xaxis.set_major_locator(ticker.MultipleLocator(3000))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gi_4crEQC7sW"
      },
      "outputs": [],
      "source": [
        "df = dfraw.ilocp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nh_q6iJeWezK"
      },
      "outputs": [],
      "source": [
        "x = dfraw.head(5)\n",
        "\n",
        "x.iloc[:,0:3].to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYZep8BibWkI"
      },
      "outputs": [],
      "source": [
        "dictionary = {'TimeStamp': {0: '2023-02-23 08:01:50.701',\n",
        "  1: '2023-02-23 08:01:50.798',\n",
        "  2: '2023-02-23 08:01:50.798',\n",
        "  3: '2023-02-23 08:01:50.800',\n",
        "  4: '2023-02-23 08:01:50.800'},\n",
        " 'Delta_TP9': {0: np.nan,\n",
        "  1: 0.8932789112449511,\n",
        "  2: 0.8932789112449511,\n",
        "  3: 0.8932789112449511,\n",
        "  4: 0.8932789112449511},\n",
        " 'Delta_AF7': {0: np.nan,\n",
        "  1: -0.062321571240896,\n",
        "  2: -0.0734485722420289,\n",
        "  3: -0.0734485722420289,\n",
        "  4: -0.0734485722420289}}\n",
        "\n",
        "dfm = pd.DataFrame.from_dict(dictionary)\n",
        "\n",
        "#dfm.rolling(3).mean()\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2dMhYH15zxO"
      },
      "outputs": [],
      "source": [
        "(df.select_dtypes('number')\n",
        "   .rolling(3).mean()\n",
        "   .join(df.select_dtypes(exclude='number'))\n",
        "   [df.columns]\n",
        " )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HrSQvm-6Hd2"
      },
      "outputs": [],
      "source": [
        "df.select_dtypes(exclude='number')[df.columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rf6gxQxeTIG_"
      },
      "outputs": [],
      "source": [
        "dfsec = df.rolling(256, min_periods=1).mean()\n",
        "dfsec.head()\n",
        "#dfs = dfsec.iloc[::30, :]\n",
        "\n",
        "df.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clPjpy_8Ub1R"
      },
      "outputs": [],
      "source": [
        "df_time = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]},\n",
        "                       index = [pd.Timestamp('20130101 09:00:00'),\n",
        "                                pd.Timestamp('20130101 09:00:02'),\n",
        "                                pd.Timestamp('20130101 09:00:03'),\n",
        "                                pd.Timestamp('20130101 09:00:05'),\n",
        "                                pd.Timestamp('20130101 09:00:06')])\n",
        "\n",
        "\n",
        "df_time.rolling(2, min_periods=1).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUdylvksf-kT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "y = [0.301, 0.477, 0.602, 0.699, 0.778, 0.845, 0.903, 0.954, 1.000, 1.044]\n",
        "\n",
        "df = pd.DataFrame({\"X\" : x, \"Log2\" : y})\n",
        "\n",
        "df.plot(x=\"X\", y=\"Log2\")\n",
        "plt.title(\"Log2 graph\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_5OJvTGe8Qg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRDBV0cwmidt"
      },
      "source": [
        "### live streaming"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "roE6nqPD7o24",
        "uIBRr19cYGpD"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}